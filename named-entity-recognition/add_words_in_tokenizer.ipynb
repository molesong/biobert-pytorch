{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test add new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['co', '##vid']\n",
      "['hospital', '##ization']\n",
      "['c', '##er']\n",
      "['p', '##hos', '##pha', '##ti', '##dy', '##l', '##cho', '##line']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = \"/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_fast=True)\n",
    "model = AutoModel.from_pretrained(model)\n",
    "\n",
    "list_ = ['COVID', 'hospitalization', 'Cer', 'Phosphatidylcholine']\n",
    "\n",
    "for word in list_:\n",
    "    print(tokenizer.tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = [\"new_tok1\", \"my_new-tok2\"]\n",
    "new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "# len(list(set(tokenizer.vocab.keys())))\n",
    "print(len(tokenizer))\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(model.embeddings.word_embeddings.weight.size())\n",
    "print(model.embeddings.word_embeddings.weight[-2:, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_lipid_list_filename = 'added_lipid_list.txt'\n",
    "with open(added_lipid_list_filename, 'r') as f:\n",
    "    added_lipid_list = f.read().splitlines()\n",
    "added_lipid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28998"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9127"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = tokenizer.convert_tokens_to_ids('entity')\n",
    "token_embedding = model.embeddings.word_embeddings.weight[token_id]\n",
    "token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['COVID', 'hospitalization','Cer','Phosphatidylcholine']\n",
    "num_added_toks = tokenizer.add_tokens(new_tokens)\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3/', vocab_size=28996, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 29000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cer']\n",
      "['phosphatidylcholine']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/tokenizer_config.json',\n",
       " '/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/special_tokens_map.json',\n",
       " '/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/vocab.txt',\n",
       " '/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/added_tokens.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "for word in new_tokens[2:]:\n",
    "    print(tokenizer.tokenize(word))\n",
    "# print(tokenizer.tokenize('Cer'))\n",
    "# print(tokenizer.tokenize('Phosphatidylcholine'))\n",
    "tokenizer.save_pretrained(\"/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish adding, test the effect of loading model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/ and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', '##ew', '##word']\n",
      "['cer']\n",
      "['phosphatidylcholine']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "model = \"/home/data/t200404/bioinfo/P_subject/NLP/biobert/biobertModelWarehouse/model_from_trained/NER/4_combine_lipid_disease_ture_combine_3_add_words_test/\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model, use_fast=True)\n",
    "model = BertForMaskedLM.from_pretrained(model)\n",
    "print(tokenizer.tokenize('anewword'))\n",
    "print(tokenizer.tokenize('Cer'))\n",
    "print(tokenizer.tokenize('Phosphatidylcholine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_11_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
