{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In line with our findings in patients, a previous study found decreased levels of 18:0-LPC in mice with NASH]\n",
      "(line, patients, mice)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ac7e6f77a3794f82978be4d493c7501f-0\" class=\"displacy\" width=\"3375\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">line</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">our</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">findings</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">patients,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">previous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">study</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">found</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">decreased</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">levels</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">18:0-LPC</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">mice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">NASH</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1800.0,2.0 1800.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod:poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-4\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-11\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2140.0,177.0 2140.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,354.0 L2148.0,342.0 2132.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,354.0 L2337,342.0 2353,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-13\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,177.0 2490.0,177.0 2490.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2490.0,354.0 L2498.0,342.0 2482.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-14\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,264.5 2835.0,264.5 2835.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-15\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,89.5 2845.0,89.5 2845.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2845.0,354.0 L2853.0,342.0 2837.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ac7e6f77a3794f82978be4d493c7501f-0-17\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,2.0 3200.0,2.0 3200.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ac7e6f77a3794f82978be4d493c7501f-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3200.0,354.0 L3208.0,342.0 3192.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "# text = \"\"\"To investigate the mechanism underlying the anti-inflammatory effects of SGDGs, we tested the NF-κB pathway because it is critical for the LPS-induced expression of pro-inflammatory cytokines. Treatment of HEK293T cells expressing TLR4 and MD2 with SGDG(14:0/16:0) significantly reduced the NF-κB reporter activity while MGDG(14:0/16:0) did not (Fig. 6d), suggesting that SGDG exerts the anti-inflammatory effects via the TLR4/MD2 mediated NF-κB pathway.\n",
    "# \"\"\"\n",
    "text=\"In line with our findings in patients, a previous study found decreased levels of 18:0-LPC in mice with NASH\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(list(doc.sents))\n",
    "print(doc.ents)\n",
    "\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "displacy.render(next(doc.sents), style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviation \t Definition\n",
      "SBMA \t (33, 34) Spinal and bulbar muscular atrophy\n",
      "SBMA \t (6, 7) Spinal and bulbar muscular atrophy\n",
      "AR \t (29, 30) androgen receptor\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "# Add the abbreviation pipe to the spacy pipeline.\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "\n",
    "doc = nlp(\"Spinal and bulbar muscular atrophy (SBMA) is an \\\n",
    "           inherited motor neuron disease caused by the expansion \\\n",
    "           of a polyglutamine tract within the androgen receptor (AR). \\\n",
    "           SBMA can be caused by this easily.\")\n",
    "text=\"In line with our findings in patients, a previous study found decreased levels of 18:0-LPC in mice with NASH\"\n",
    "print(\"Abbreviation\", \"\\t\", \"Definition\")\n",
    "for abrv in doc._.abbreviations:\n",
    "\tprint(f\"{abrv} \\t ({abrv.start}, {abrv.end}) {abrv._.long_form}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on English in module spacy.lang.en object:\n",
      "\n",
      "class English(spacy.language.Language)\n",
      " |  English(vocab: Union[spacy.vocab.Vocab, bool] = True, *, max_length: int = 1000000, meta: Dict[str, Any] = {}, create_tokenizer: Union[Callable[[ForwardRef('Language')], Callable[[str], spacy.tokens.doc.Doc]], NoneType] = None, create_vectors: Union[Callable[[ForwardRef('Vocab')], spacy.vectors.BaseVectors], NoneType] = None, batch_size: int = 1000, **kwargs) -> None\n",
      " |  \n",
      " |  A text-processing pipeline. Usually you'll load this once per process,\n",
      " |  and pass the instance around your application.\n",
      " |  \n",
      " |  Defaults (class): Settings, data and factory methods for creating the `nlp`\n",
      " |      object and processing pipeline.\n",
      " |  lang (str): IETF language code, such as 'en'.\n",
      " |  \n",
      " |  DOCS: https://spacy.io/api/language\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      English\n",
      " |      spacy.language.Language\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  Defaults = <class 'spacy.lang.en.EnglishDefaults'>\n",
      " |      Language data defaults, available via Language.Defaults. Can be\n",
      " |      overwritten by language subclasses by defining their own subclasses of\n",
      " |      Language.Defaults.\n",
      " |  \n",
      " |  default_config = {'paths': {'train': None, 'dev': None, 'vectors'...s'...\n",
      " |  \n",
      " |  factories = {'attribute_ruler': <function make_attribute_rul...r': <fu...\n",
      " |  \n",
      " |  lang = 'en'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from spacy.language.Language:\n",
      " |  \n",
      " |  __call__(self, text: Union[str, spacy.tokens.doc.Doc], *, disable: Iterable[str] = [], component_cfg: Union[Dict[str, Dict[str, Any]], NoneType] = None) -> spacy.tokens.doc.Doc\n",
      " |      Apply the pipeline to some text. The text can span multiple sentences,\n",
      " |      and can contain arbitrary whitespace. Alignment into the original string\n",
      " |      is preserved.\n",
      " |      \n",
      " |      text (Union[str, Doc]): If `str`, the text to be processed. If `Doc`,\n",
      " |          the doc will be passed directly to the pipeline, skipping\n",
      " |          `Language.make_doc`.\n",
      " |      disable (List[str]): Names of the pipeline components to disable.\n",
      " |      component_cfg (Dict[str, dict]): An optional dictionary with extra\n",
      " |          keyword arguments for specific components.\n",
      " |      RETURNS (Doc): A container for accessing the annotations.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#call\n",
      " |  \n",
      " |  __init__(self, vocab: Union[spacy.vocab.Vocab, bool] = True, *, max_length: int = 1000000, meta: Dict[str, Any] = {}, create_tokenizer: Union[Callable[[ForwardRef('Language')], Callable[[str], spacy.tokens.doc.Doc]], NoneType] = None, create_vectors: Union[Callable[[ForwardRef('Vocab')], spacy.vectors.BaseVectors], NoneType] = None, batch_size: int = 1000, **kwargs) -> None\n",
      " |      Initialise a Language object.\n",
      " |      \n",
      " |      vocab (Vocab): A `Vocab` object. If `True`, a vocab is created.\n",
      " |      meta (dict): Custom meta data for the Language class. Is written to by\n",
      " |          models to add model meta data.\n",
      " |      max_length (int): Maximum number of characters in a single text. The\n",
      " |          current models may run out memory on extremely long texts, due to\n",
      " |          large internal allocations. You should segment these texts into\n",
      " |          meaningful units, e.g. paragraphs, subsections etc, before passing\n",
      " |          them to spaCy. Default maximum length is 1,000,000 charas (1mb). As\n",
      " |          a rule of thumb, if all pipeline components are enabled, spaCy's\n",
      " |          default models currently requires roughly 1GB of temporary memory per\n",
      " |          100,000 characters in one text.\n",
      " |      create_tokenizer (Callable): Function that takes the nlp object and\n",
      " |          returns a tokenizer.\n",
      " |      batch_size (int): Default batch size for pipe and evaluate.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#init\n",
      " |  \n",
      " |  add_pipe(self, factory_name: str, name: Union[str, NoneType] = None, *, before: Union[str, int, NoneType] = None, after: Union[str, int, NoneType] = None, first: Union[bool, NoneType] = None, last: Union[bool, NoneType] = None, source: Union[ForwardRef('Language'), NoneType] = None, config: Dict[str, Any] = {}, raw_config: Union[confection.Config, NoneType] = None, validate: bool = True) -> Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc]\n",
      " |      Add a component to the processing pipeline. Valid components are\n",
      " |      callables that take a `Doc` object, modify it and return it. Only one\n",
      " |      of before/after/first/last can be set. Default behaviour is \"last\".\n",
      " |      \n",
      " |      factory_name (str): Name of the component factory.\n",
      " |      name (str): Name of pipeline component. Overwrites existing\n",
      " |          component.name attribute if available. If no name is set and\n",
      " |          the component exposes no name attribute, component.__name__ is\n",
      " |          used. An error is raised if a name already exists in the pipeline.\n",
      " |      before (Union[str, int]): Name or index of the component to insert new\n",
      " |          component directly before.\n",
      " |      after (Union[str, int]): Name or index of the component to insert new\n",
      " |          component directly after.\n",
      " |      first (bool): If True, insert component first in the pipeline.\n",
      " |      last (bool): If True, insert component last in the pipeline.\n",
      " |      source (Language): Optional loaded nlp object to copy the pipeline\n",
      " |          component from.\n",
      " |      config (Dict[str, Any]): Config parameters to use for this component.\n",
      " |          Will be merged with default config, if available.\n",
      " |      raw_config (Optional[Config]): Internals: the non-interpolated config.\n",
      " |      validate (bool): Whether to validate the component config against the\n",
      " |          arguments and types expected by the factory.\n",
      " |      RETURNS (Callable[[Doc], Doc]): The pipeline component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#add_pipe\n",
      " |  \n",
      " |  analyze_pipes(self, *, keys: List[str] = ['assigns', 'requires', 'scores', 'retokenizes'], pretty: bool = False) -> Union[Dict[str, Any], NoneType]\n",
      " |      Analyze the current pipeline components, print a summary of what\n",
      " |      they assign or require and check that all requirements are met.\n",
      " |      \n",
      " |      keys (List[str]): The meta values to display in the table. Corresponds\n",
      " |          to values in FactoryMeta, defined by @Language.factory decorator.\n",
      " |      pretty (bool): Pretty-print the results.\n",
      " |      RETURNS (dict): The data.\n",
      " |  \n",
      " |  begin_training(self, get_examples: Union[Callable[[], Iterable[spacy.training.example.Example]], NoneType] = None, *, sgd: Union[thinc.optimizers.Optimizer, NoneType] = None) -> thinc.optimizers.Optimizer\n",
      " |  \n",
      " |  create_optimizer(self)\n",
      " |      Create an optimizer, usually using the [training.optimizer] config.\n",
      " |  \n",
      " |  create_pipe(self, factory_name: str, name: Union[str, NoneType] = None, *, config: Dict[str, Any] = {}, raw_config: Union[confection.Config, NoneType] = None, validate: bool = True) -> Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc]\n",
      " |      Create a pipeline component. Mostly used internally. To create and\n",
      " |      add a component to the pipeline, you can use nlp.add_pipe.\n",
      " |      \n",
      " |      factory_name (str): Name of component factory.\n",
      " |      name (Optional[str]): Optional name to assign to component instance.\n",
      " |          Defaults to factory name if not set.\n",
      " |      config (Dict[str, Any]): Config parameters to use for this component.\n",
      " |          Will be merged with default config, if available.\n",
      " |      raw_config (Optional[Config]): Internals: the non-interpolated config.\n",
      " |      validate (bool): Whether to validate the component config against the\n",
      " |          arguments and types expected by the factory.\n",
      " |      RETURNS (Callable[[Doc], Doc]): The pipeline component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#create_pipe\n",
      " |  \n",
      " |  create_pipe_from_source(self, source_name: str, source: 'Language', *, name: str) -> Tuple[Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc], str]\n",
      " |      Create a pipeline component by copying it from an existing model.\n",
      " |      \n",
      " |      source_name (str): Name of the component in the source pipeline.\n",
      " |      source (Language): The source nlp object to copy from.\n",
      " |      name (str): Optional alternative name to use in current pipeline.\n",
      " |      RETURNS (Tuple[Callable[[Doc], Doc], str]): The component and its factory name.\n",
      " |  \n",
      " |  disable_pipe(self, name: str) -> None\n",
      " |      Disable a pipeline component. The component will still exist on\n",
      " |      the nlp object, but it won't be run as part of the pipeline. Does\n",
      " |      nothing if the component is already disabled.\n",
      " |      \n",
      " |      name (str): The name of the component to disable.\n",
      " |  \n",
      " |  disable_pipes(self, *names) -> 'DisabledPipes'\n",
      " |      Disable one or more pipeline components. If used as a context\n",
      " |      manager, the pipeline will be restored to the initial state at the end\n",
      " |      of the block. Otherwise, a DisabledPipes object is returned, that has\n",
      " |      a `.restore()` method you can use to undo your changes.\n",
      " |      \n",
      " |      This method has been deprecated since 3.0\n",
      " |  \n",
      " |  enable_pipe(self, name: str) -> None\n",
      " |      Enable a previously disabled pipeline component so it's run as part\n",
      " |      of the pipeline. Does nothing if the component is already enabled.\n",
      " |      \n",
      " |      name (str): The name of the component to enable.\n",
      " |  \n",
      " |  evaluate(self, examples: Iterable[spacy.training.example.Example], *, batch_size: Union[int, NoneType] = None, scorer: Union[spacy.scorer.Scorer, NoneType] = None, component_cfg: Union[Dict[str, Dict[str, Any]], NoneType] = None, scorer_cfg: Union[Dict[str, Any], NoneType] = None, per_component: bool = False) -> Dict[str, Any]\n",
      " |      Evaluate a model's pipeline components.\n",
      " |      \n",
      " |      examples (Iterable[Example]): `Example` objects.\n",
      " |      batch_size (Optional[int]): Batch size to use.\n",
      " |      scorer (Optional[Scorer]): Scorer to use. If not passed in, a new one\n",
      " |          will be created.\n",
      " |      component_cfg (dict): An optional dictionary with extra keyword\n",
      " |          arguments for specific components.\n",
      " |      scorer_cfg (dict): An optional dictionary with extra keyword arguments\n",
      " |          for the scorer.\n",
      " |      per_component (bool): Whether to return the scores keyed by component\n",
      " |          name. Defaults to False.\n",
      " |      \n",
      " |      RETURNS (Scorer): The scorer containing the evaluation results.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#evaluate\n",
      " |  \n",
      " |  from_bytes(self, bytes_data: bytes, *, exclude: Iterable[str] = []) -> 'Language'\n",
      " |      Load state from a binary string.\n",
      " |      \n",
      " |      bytes_data (bytes): The data to load from.\n",
      " |      exclude (Iterable[str]): Names of components or serialization fields to exclude.\n",
      " |      RETURNS (Language): The `Language` object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#from_bytes\n",
      " |  \n",
      " |  from_disk(self, path: Union[str, pathlib.Path], *, exclude: Iterable[str] = [], overrides: Dict[str, Any] = {}) -> 'Language'\n",
      " |      Loads state from a directory. Modifies the object in place and\n",
      " |      returns it. If the saved `Language` object contains a model, the\n",
      " |      model will be loaded.\n",
      " |      \n",
      " |      path (str / Path): A path to a directory.\n",
      " |      exclude (Iterable[str]): Names of components or serialization fields to exclude.\n",
      " |      RETURNS (Language): The modified `Language` object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#from_disk\n",
      " |  \n",
      " |  get_pipe(self, name: str) -> Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc]\n",
      " |      Get a pipeline component for a given component name.\n",
      " |      \n",
      " |      name (str): Name of pipeline component to get.\n",
      " |      RETURNS (callable): The pipeline component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#get_pipe\n",
      " |  \n",
      " |  get_pipe_config(self, name: str) -> confection.Config\n",
      " |      Get the config used to create a pipeline component.\n",
      " |      \n",
      " |      name (str): The component name.\n",
      " |      RETURNS (Config): The config used to create the pipeline component.\n",
      " |  \n",
      " |  get_pipe_meta(self, name: str) -> 'FactoryMeta'\n",
      " |      Get the meta information for a given component name.\n",
      " |      \n",
      " |      name (str): The component name.\n",
      " |      RETURNS (FactoryMeta): The meta for the given component name.\n",
      " |  \n",
      " |  has_pipe(self, name: str) -> bool\n",
      " |      Check if a component name is present in the pipeline. Equivalent to\n",
      " |      `name in nlp.pipe_names`.\n",
      " |      \n",
      " |      name (str): Name of the component.\n",
      " |      RETURNS (bool): Whether a component of the name exists in the pipeline.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#has_pipe\n",
      " |  \n",
      " |  initialize(self, get_examples: Union[Callable[[], Iterable[spacy.training.example.Example]], NoneType] = None, *, sgd: Union[thinc.optimizers.Optimizer, NoneType] = None) -> thinc.optimizers.Optimizer\n",
      " |      Initialize the pipe for training, using data examples if available.\n",
      " |      \n",
      " |      get_examples (Callable[[], Iterable[Example]]): Optional function that\n",
      " |          returns gold-standard Example objects.\n",
      " |      sgd (Optional[Optimizer]): An optimizer to use for updates. If not\n",
      " |          provided, will be created using the .create_optimizer() method.\n",
      " |      RETURNS (thinc.api.Optimizer): The optimizer.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#initialize\n",
      " |  \n",
      " |  make_doc(self, text: str) -> spacy.tokens.doc.Doc\n",
      " |      Turn a text into a Doc object.\n",
      " |      \n",
      " |      text (str): The text to process.\n",
      " |      RETURNS (Doc): The processed doc.\n",
      " |  \n",
      " |  pipe(self, texts: Union[Iterable[Union[str, spacy.tokens.doc.Doc]], Iterable[Tuple[Union[str, spacy.tokens.doc.Doc], ~_AnyContext]]], *, as_tuples: bool = False, batch_size: Union[int, NoneType] = None, disable: Iterable[str] = [], component_cfg: Union[Dict[str, Dict[str, Any]], NoneType] = None, n_process: int = 1) -> Union[Iterator[spacy.tokens.doc.Doc], Iterator[Tuple[spacy.tokens.doc.Doc, ~_AnyContext]]]\n",
      " |      Process texts as a stream, and yield `Doc` objects in order.\n",
      " |      \n",
      " |      texts (Iterable[Union[str, Doc]]): A sequence of texts or docs to\n",
      " |          process.\n",
      " |      as_tuples (bool): If set to True, inputs should be a sequence of\n",
      " |          (text, context) tuples. Output will then be a sequence of\n",
      " |          (doc, context) tuples. Defaults to False.\n",
      " |      batch_size (Optional[int]): The number of texts to buffer.\n",
      " |      disable (List[str]): Names of the pipeline components to disable.\n",
      " |      component_cfg (Dict[str, Dict]): An optional dictionary with extra keyword\n",
      " |          arguments for specific components.\n",
      " |      n_process (int): Number of processors to process texts. If -1, set `multiprocessing.cpu_count()`.\n",
      " |      YIELDS (Doc): Documents in the order of the original text.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#pipe\n",
      " |  \n",
      " |  rehearse(self, examples: Iterable[spacy.training.example.Example], *, sgd: Union[thinc.optimizers.Optimizer, NoneType] = None, losses: Union[Dict[str, float], NoneType] = None, component_cfg: Union[Dict[str, Dict[str, Any]], NoneType] = None, exclude: Iterable[str] = []) -> Dict[str, float]\n",
      " |      Make a \"rehearsal\" update to the models in the pipeline, to prevent\n",
      " |      forgetting. Rehearsal updates run an initial copy of the model over some\n",
      " |      data, and update the model so its current predictions are more like the\n",
      " |      initial ones. This is useful for keeping a pretrained model on-track,\n",
      " |      even if you're updating it with a smaller set of examples.\n",
      " |      \n",
      " |      examples (Iterable[Example]): A batch of `Example` objects.\n",
      " |      sgd (Optional[Optimizer]): An optimizer.\n",
      " |      component_cfg (Dict[str, Dict]): Config parameters for specific pipeline\n",
      " |          components, keyed by component name.\n",
      " |      exclude (Iterable[str]): Names of components that shouldn't be updated.\n",
      " |      RETURNS (dict): Results from the update.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> raw_text_batches = minibatch(raw_texts)\n",
      " |          >>> for labelled_batch in minibatch(examples):\n",
      " |          >>>     nlp.update(labelled_batch)\n",
      " |          >>>     raw_batch = [Example.from_dict(nlp.make_doc(text), {}) for text in next(raw_text_batches)]\n",
      " |          >>>     nlp.rehearse(raw_batch)\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#rehearse\n",
      " |  \n",
      " |  remove_pipe(self, name: str) -> Tuple[str, Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc]]\n",
      " |      Remove a component from the pipeline.\n",
      " |      \n",
      " |      name (str): Name of the component to remove.\n",
      " |      RETURNS (Tuple[str, Callable[[Doc], Doc]]): A `(name, component)` tuple of the removed component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#remove_pipe\n",
      " |  \n",
      " |  rename_pipe(self, old_name: str, new_name: str) -> None\n",
      " |      Rename a pipeline component.\n",
      " |      \n",
      " |      old_name (str): Name of the component to rename.\n",
      " |      new_name (str): New name of the component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#rename_pipe\n",
      " |  \n",
      " |  replace_listeners(self, tok2vec_name: str, pipe_name: str, listeners: Iterable[str]) -> None\n",
      " |      Find listener layers (connecting to a token-to-vector embedding\n",
      " |      component) of a given pipeline component model and replace\n",
      " |      them with a standalone copy of the token-to-vector layer. This can be\n",
      " |      useful when training a pipeline with components sourced from an existing\n",
      " |      pipeline: if multiple components (e.g. tagger, parser, NER) listen to\n",
      " |      the same tok2vec component, but some of them are frozen and not updated,\n",
      " |      their performance may degrade significantly as the tok2vec component is\n",
      " |      updated with new data. To prevent this, listeners can be replaced with\n",
      " |      a standalone tok2vec layer that is owned by the component and doesn't\n",
      " |      change if the component isn't updated.\n",
      " |      \n",
      " |      tok2vec_name (str): Name of the token-to-vector component, typically\n",
      " |          \"tok2vec\" or \"transformer\".\n",
      " |      pipe_name (str): Name of pipeline component to replace listeners for.\n",
      " |      listeners (Iterable[str]): The paths to the listeners, relative to the\n",
      " |          component config, e.g. [\"model.tok2vec\"]. Typically, implementations\n",
      " |          will only connect to one tok2vec component, [model.tok2vec], but in\n",
      " |          theory, custom models can use multiple listeners. The value here can\n",
      " |          either be an empty list to not replace any listeners, or a complete\n",
      " |          (!) list of the paths to all listener layers used by the model.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#replace_listeners\n",
      " |  \n",
      " |  replace_pipe(self, name: str, factory_name: str, *, config: Dict[str, Any] = {}, validate: bool = True) -> Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc]\n",
      " |      Replace a component in the pipeline.\n",
      " |      \n",
      " |      name (str): Name of the component to replace.\n",
      " |      factory_name (str): Factory name of replacement component.\n",
      " |      config (Optional[Dict[str, Any]]): Config parameters to use for this\n",
      " |          component. Will be merged with default config, if available.\n",
      " |      validate (bool): Whether to validate the component config against the\n",
      " |          arguments and types expected by the factory.\n",
      " |      RETURNS (Callable[[Doc], Doc]): The new pipeline component.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#replace_pipe\n",
      " |  \n",
      " |  resume_training(self, *, sgd: Union[thinc.optimizers.Optimizer, NoneType] = None) -> thinc.optimizers.Optimizer\n",
      " |      Continue training a pretrained model.\n",
      " |      \n",
      " |      Create and return an optimizer, and initialize \"rehearsal\" for any pipeline\n",
      " |      component that has a .rehearse() method. Rehearsal is used to prevent\n",
      " |      models from \"forgetting\" their initialized \"knowledge\". To perform\n",
      " |      rehearsal, collect samples of text you want the models to retain performance\n",
      " |      on, and call nlp.rehearse() with a batch of Example objects.\n",
      " |      \n",
      " |      RETURNS (Optimizer): The optimizer.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#resume_training\n",
      " |  \n",
      " |  select_pipes(self, *, disable: Union[str, Iterable[str], NoneType] = None, enable: Union[str, Iterable[str], NoneType] = None) -> 'DisabledPipes'\n",
      " |      Disable one or more pipeline components. If used as a context\n",
      " |      manager, the pipeline will be restored to the initial state at the end\n",
      " |      of the block. Otherwise, a DisabledPipes object is returned, that has\n",
      " |      a `.restore()` method you can use to undo your changes.\n",
      " |      \n",
      " |      disable (str or iterable): The name(s) of the pipes to disable\n",
      " |      enable (str or iterable): The name(s) of the pipes to enable - all others will be disabled\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#select_pipes\n",
      " |  \n",
      " |  set_error_handler(self, error_handler: Callable[[str, Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc], List[spacy.tokens.doc.Doc], Exception], NoReturn])\n",
      " |      Set an error handler object for all the components in the pipeline\n",
      " |      that implement a set_error_handler function.\n",
      " |      \n",
      " |      error_handler (Callable[[str, Callable[[Doc], Doc], List[Doc], Exception], NoReturn]):\n",
      " |          Function that deals with a failing batch of documents. This callable\n",
      " |          function should take in the component's name, the component itself,\n",
      " |          the offending batch of documents, and the exception that was thrown.\n",
      " |      DOCS: https://spacy.io/api/language#set_error_handler\n",
      " |  \n",
      " |  to_bytes(self, *, exclude: Iterable[str] = []) -> bytes\n",
      " |      Serialize the current state to a binary string.\n",
      " |      \n",
      " |      exclude (Iterable[str]): Names of components or serialization fields to exclude.\n",
      " |      RETURNS (bytes): The serialized form of the `Language` object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#to_bytes\n",
      " |  \n",
      " |  to_disk(self, path: Union[str, pathlib.Path], *, exclude: Iterable[str] = []) -> None\n",
      " |      Save the current state to a directory.  If a model is loaded, this\n",
      " |      will include the model.\n",
      " |      \n",
      " |      path (str / Path): Path to a directory, which will be created if\n",
      " |          it doesn't exist.\n",
      " |      exclude (Iterable[str]): Names of components or serialization fields to exclude.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#to_disk\n",
      " |  \n",
      " |  update(self, examples: Iterable[spacy.training.example.Example], _: Union[Any, NoneType] = None, *, drop: float = 0.0, sgd: Union[thinc.optimizers.Optimizer, NoneType] = None, losses: Union[Dict[str, float], NoneType] = None, component_cfg: Union[Dict[str, Dict[str, Any]], NoneType] = None, exclude: Iterable[str] = [], annotates: Iterable[str] = [])\n",
      " |      Update the models in the pipeline.\n",
      " |      \n",
      " |      examples (Iterable[Example]): A batch of examples\n",
      " |      _: Should not be set - serves to catch backwards-incompatible scripts.\n",
      " |      drop (float): The dropout rate.\n",
      " |      sgd (Optimizer): An optimizer.\n",
      " |      losses (Dict[str, float]): Dictionary to update with the loss, keyed by\n",
      " |          component.\n",
      " |      component_cfg (Dict[str, Dict]): Config parameters for specific pipeline\n",
      " |          components, keyed by component name.\n",
      " |      exclude (Iterable[str]): Names of components that shouldn't be updated.\n",
      " |      annotates (Iterable[str]): Names of components that should set\n",
      " |          annotations on the predicted examples after updating.\n",
      " |      RETURNS (Dict[str, float]): The updated losses dictionary\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#update\n",
      " |  \n",
      " |  use_params(self, params: Union[dict, NoneType])\n",
      " |      Replace weights of models in the pipeline with those provided in the\n",
      " |      params dictionary. Can be used as a contextmanager, in which case,\n",
      " |      models go back to their original weights after the block.\n",
      " |      \n",
      " |      params (dict): A dictionary of parameters keyed by model ID.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> with nlp.use_params(optimizer.averages):\n",
      " |          >>>     nlp.to_disk(\"/tmp/checkpoint\")\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#use_params\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from spacy.language.Language:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  component(name: str, *, assigns: Iterable[str] = [], requires: Iterable[str] = [], retokenizes: bool = False, func: Union[Callable[[spacy.tokens.doc.Doc], spacy.tokens.doc.Doc], NoneType] = None) -> Callable[..., Any] from builtins.type\n",
      " |      Register a new pipeline component. Can be used for stateless function\n",
      " |      components that don't require a separate factory. Can be used as a\n",
      " |      decorator on a function or classmethod, or called as a function with the\n",
      " |      factory provided as the func keyword argument. To create a component and\n",
      " |      add it to the pipeline, you can use nlp.add_pipe(name).\n",
      " |      \n",
      " |      name (str): The name of the component factory.\n",
      " |      assigns (Iterable[str]): Doc/Token attributes assigned by this component,\n",
      " |          e.g. \"token.ent_id\". Used for pipeline analysis.\n",
      " |      requires (Iterable[str]): Doc/Token attributes required by this component,\n",
      " |          e.g. \"token.ent_id\". Used for pipeline analysis.\n",
      " |      retokenizes (bool): Whether the component changes the tokenization.\n",
      " |          Used for pipeline analysis.\n",
      " |      func (Optional[Callable[[Doc], Doc]): Factory function if not used as a decorator.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#component\n",
      " |  \n",
      " |  factory(name: str, *, default_config: Dict[str, Any] = {}, assigns: Iterable[str] = [], requires: Iterable[str] = [], retokenizes: bool = False, default_score_weights: Dict[str, Union[float, NoneType]] = {}, func: Union[Callable, NoneType] = None) -> Callable from builtins.type\n",
      " |      Register a new pipeline component factory. Can be used as a decorator\n",
      " |      on a function or classmethod, or called as a function with the factory\n",
      " |      provided as the func keyword argument. To create a component and add\n",
      " |      it to the pipeline, you can use nlp.add_pipe(name).\n",
      " |      \n",
      " |      name (str): The name of the component factory.\n",
      " |      default_config (Dict[str, Any]): Default configuration, describing the\n",
      " |          default values of the factory arguments.\n",
      " |      assigns (Iterable[str]): Doc/Token attributes assigned by this component,\n",
      " |          e.g. \"token.ent_id\". Used for pipeline analysis.\n",
      " |      requires (Iterable[str]): Doc/Token attributes required by this component,\n",
      " |          e.g. \"token.ent_id\". Used for pipeline analysis.\n",
      " |      retokenizes (bool): Whether the component changes the tokenization.\n",
      " |          Used for pipeline analysis.\n",
      " |      default_score_weights (Dict[str, Optional[float]]): The scores to report during\n",
      " |          training, and their default weight towards the final score used to\n",
      " |          select the best model. Weights should sum to 1.0 per component and\n",
      " |          will be combined and normalized for the whole pipeline. If None,\n",
      " |          the score won't be shown in the logs or be weighted.\n",
      " |      func (Optional[Callable]): Factory function if not used as a decorator.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#factory\n",
      " |  \n",
      " |  from_config(config: Union[Dict[str, Any], confection.Config] = {}, *, vocab: Union[spacy.vocab.Vocab, bool] = True, disable: Union[str, Iterable[str]] = [], enable: Union[str, Iterable[str]] = [], exclude: Union[str, Iterable[str]] = [], meta: Dict[str, Any] = {}, auto_fill: bool = True, validate: bool = True) -> 'Language' from builtins.type\n",
      " |      Create the nlp object from a loaded config. Will set up the tokenizer\n",
      " |      and language data, add pipeline components etc. If no config is provided,\n",
      " |      the default config of the given language is used.\n",
      " |      \n",
      " |      config (Dict[str, Any] / Config): The loaded config.\n",
      " |      vocab (Vocab): A Vocab object. If True, a vocab is created.\n",
      " |      disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.\n",
      " |          Disabled pipes will be loaded but they won't be run unless you\n",
      " |          explicitly enable them by calling nlp.enable_pipe.\n",
      " |      enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\n",
      " |          pipes will be disabled (and can be enabled using `nlp.enable_pipe`).\n",
      " |      exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude.\n",
      " |          Excluded components won't be loaded.\n",
      " |      meta (Dict[str, Any]): Meta overrides for nlp.meta.\n",
      " |      auto_fill (bool): Automatically fill in missing values in config based\n",
      " |          on defaults and function argument annotations.\n",
      " |      validate (bool): Validate the component config and arguments against\n",
      " |          the types expected by the factory.\n",
      " |      RETURNS (Language): The initialized Language class.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#from_config\n",
      " |  \n",
      " |  get_factory_meta(name: str) -> 'FactoryMeta' from builtins.type\n",
      " |      Get the meta information for a given factory name.\n",
      " |      \n",
      " |      name (str): The component factory name.\n",
      " |      RETURNS (FactoryMeta): The meta for the given factory name.\n",
      " |  \n",
      " |  get_factory_name(name: str) -> str from builtins.type\n",
      " |      Get the internal factory name based on the language subclass.\n",
      " |      \n",
      " |      name (str): The factory name.\n",
      " |      RETURNS (str): The internal factory name.\n",
      " |  \n",
      " |  has_factory(name: str) -> bool from builtins.type\n",
      " |      RETURNS (bool): Whether a factory of that name is registered.\n",
      " |  \n",
      " |  set_factory_meta(name: str, value: 'FactoryMeta') -> None from builtins.type\n",
      " |      Set the meta information for a given factory name.\n",
      " |      \n",
      " |      name (str): The component factory name.\n",
      " |      value (FactoryMeta): The meta to set.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from spacy.language.Language:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  component_names\n",
      " |      Get the names of the available pipeline components. Includes all\n",
      " |      active and inactive pipeline components.\n",
      " |      \n",
      " |      RETURNS (List[str]): List of component name strings, in order.\n",
      " |  \n",
      " |  components\n",
      " |      Get all (name, component) tuples in the pipeline, including the\n",
      " |      currently disabled components.\n",
      " |  \n",
      " |  config\n",
      " |      Trainable config for the current language instance. Includes the\n",
      " |      current pipeline components, as well as default training config.\n",
      " |      \n",
      " |      RETURNS (thinc.api.Config): The config.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#config\n",
      " |  \n",
      " |  disabled\n",
      " |      Get the names of all disabled components.\n",
      " |      \n",
      " |      RETURNS (List[str]): The disabled components.\n",
      " |  \n",
      " |  factory_names\n",
      " |      Get names of all available factories.\n",
      " |      \n",
      " |      RETURNS (List[str]): The factory names.\n",
      " |  \n",
      " |  meta\n",
      " |      Custom meta data of the language class. If a model is loaded, this\n",
      " |      includes details from the model's meta.json.\n",
      " |      \n",
      " |      RETURNS (Dict[str, Any]): The meta.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/language#meta\n",
      " |  \n",
      " |  path\n",
      " |  \n",
      " |  pipe_factories\n",
      " |      Get the component factories for the available pipeline components.\n",
      " |      \n",
      " |      RETURNS (Dict[str, str]): Factory names, keyed by component names.\n",
      " |  \n",
      " |  pipe_labels\n",
      " |      Get the labels set by the pipeline components, if available (if\n",
      " |      the component exposes a labels property and the labels are not\n",
      " |      hidden).\n",
      " |      \n",
      " |      RETURNS (Dict[str, List[str]]): Labels keyed by component name.\n",
      " |  \n",
      " |  pipe_names\n",
      " |      Get names of available active pipeline components.\n",
      " |      \n",
      " |      RETURNS (List[str]): List of component name strings, in order.\n",
      " |  \n",
      " |  pipeline\n",
      " |      The processing pipeline consisting of (name, component) tuples. The\n",
      " |      components are called on the Doc in order as it passes through the\n",
      " |      pipeline.\n",
      " |      \n",
      " |      RETURNS (List[Tuple[str, Callable[[Doc], Doc]]]): The pipeline.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from spacy.language.Language:\n",
      " |  \n",
      " |  __annotations__ = {'_factory_meta': typing.Dict[str, ForwardRef('Facto...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dir(nlp)\n",
    "help(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_config': {'paths': {'vectors': 'output/en_core_sci_md_vectors',\n",
       "   'init_tok2vec': None,\n",
       "   'parser_tagger_path': 'output/en_core_sci_md_parser_tagger/model-best',\n",
       "   'dev_path': 'assets/BC5CDR-IOB/devel.tsv',\n",
       "   'train_path': 'assets/BC5CDR-IOB/train.tsv',\n",
       "   'vocab_path': 'project_data/vocab_md.jsonl',\n",
       "   'train': None,\n",
       "   'dev': None},\n",
       "  'system': {'gpu_allocator': None, 'seed': 0},\n",
       "  'nlp': {'lang': 'en',\n",
       "   'pipeline': ['tok2vec',\n",
       "    'tagger',\n",
       "    'attribute_ruler',\n",
       "    'lemmatizer',\n",
       "    'parser',\n",
       "    'ner'],\n",
       "   'tokenizer': {'@tokenizers': 'spacy.Tokenizer.v1'},\n",
       "   'disabled': [],\n",
       "   'before_creation': None,\n",
       "   'after_creation': None,\n",
       "   'after_pipeline_creation': None,\n",
       "   'batch_size': 1000,\n",
       "   'vectors': {'@vectors': 'spacy.Vectors.v1'}},\n",
       "  'components': {'attribute_ruler': {'factory': 'attribute_ruler',\n",
       "    'scorer': {'@scorers': 'spacy.attribute_ruler_scorer.v1'},\n",
       "    'validate': False},\n",
       "   'lemmatizer': {'factory': 'lemmatizer',\n",
       "    'mode': 'rule',\n",
       "    'model': None,\n",
       "    'overwrite': False,\n",
       "    'scorer': {'@scorers': 'spacy.lemmatizer_scorer.v1'}},\n",
       "   'ner': {'factory': 'ner',\n",
       "    'incorrect_spans_key': None,\n",
       "    'moves': None,\n",
       "    'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       "    'update_with_oracle_cut_size': 100,\n",
       "    'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "     'state_type': 'ner',\n",
       "     'extra_state_tokens': False,\n",
       "     'hidden_width': 128,\n",
       "     'maxout_pieces': 3,\n",
       "     'use_upper': True,\n",
       "     'nO': None,\n",
       "     'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "      'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "       'width': 96,\n",
       "       'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "       'rows': [5000, 2500, 2500, 2500, 100],\n",
       "       'include_static_vectors': '${vars.include_static_vectors}'},\n",
       "      'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "       'width': 96,\n",
       "       'depth': 4,\n",
       "       'window_size': 1,\n",
       "       'maxout_pieces': 3}}}},\n",
       "   'parser': {'factory': 'parser',\n",
       "    'learn_tokens': False,\n",
       "    'min_action_freq': 30,\n",
       "    'moves': None,\n",
       "    'scorer': {'@scorers': 'spacy.parser_scorer.v1'},\n",
       "    'update_with_oracle_cut_size': 100,\n",
       "    'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "     'state_type': 'parser',\n",
       "     'extra_state_tokens': False,\n",
       "     'hidden_width': 128,\n",
       "     'maxout_pieces': 3,\n",
       "     'use_upper': True,\n",
       "     'nO': None,\n",
       "     'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "      'width': 96,\n",
       "      'upstream': '*'}}},\n",
       "   'tagger': {'factory': 'tagger',\n",
       "    'label_smoothing': 0.0,\n",
       "    'neg_prefix': '!',\n",
       "    'overwrite': False,\n",
       "    'scorer': {'@scorers': 'spacy.tagger_scorer.v1'},\n",
       "    'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "     'nO': None,\n",
       "     'normalize': 'False',\n",
       "     'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "      'width': 96,\n",
       "      'upstream': '*'}}},\n",
       "   'tok2vec': {'factory': 'tok2vec',\n",
       "    'model': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "     'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "      'width': 96,\n",
       "      'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY', 'IS_SPACE'],\n",
       "      'rows': [5000, 1000, 2500, 2500, 50, 50],\n",
       "      'include_static_vectors': 'True'},\n",
       "     'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "      'width': 96,\n",
       "      'depth': 4,\n",
       "      'window_size': 1,\n",
       "      'maxout_pieces': 3}}}},\n",
       "  'corpora': {'dev': {'@readers': 'specialized_ner_reader',\n",
       "    'file_path': '${paths.dev_path}'},\n",
       "   'train': {'@readers': 'specialized_ner_reader',\n",
       "    'file_path': '${paths.train_path}'}},\n",
       "  'training': {'dev_corpus': 'corpora.dev',\n",
       "   'train_corpus': 'corpora.train',\n",
       "   'seed': '${system.seed}',\n",
       "   'gpu_allocator': '${system.gpu_allocator}',\n",
       "   'dropout': 0.1,\n",
       "   'accumulate_gradient': 1,\n",
       "   'patience': 0,\n",
       "   'max_epochs': 7,\n",
       "   'max_steps': 0,\n",
       "   'eval_frequency': 500,\n",
       "   'frozen_components': ['tok2vec',\n",
       "    'parser',\n",
       "    'tagger',\n",
       "    'attribute_ruler',\n",
       "    'lemmatizer'],\n",
       "   'before_to_disk': None,\n",
       "   'annotating_components': [],\n",
       "   'before_update': None,\n",
       "   'batcher': {'@batchers': 'spacy.batch_by_sequence.v1',\n",
       "    'get_length': None,\n",
       "    'size': {'@schedules': 'compounding.v1',\n",
       "     'start': 1,\n",
       "     'stop': 32,\n",
       "     'compound': 1.001,\n",
       "     't': 0.0}},\n",
       "   'logger': {'@loggers': 'spacy.ConsoleLogger.v1', 'progress_bar': True},\n",
       "   'optimizer': {'@optimizers': 'Adam.v1',\n",
       "    'beta1': 0.9,\n",
       "    'beta2': 0.999,\n",
       "    'L2_is_weight_decay': True,\n",
       "    'L2': 0.01,\n",
       "    'grad_clip': 1.0,\n",
       "    'use_averages': False,\n",
       "    'eps': 1e-08,\n",
       "    'learn_rate': 0.001},\n",
       "   'score_weights': {'tag_acc': None,\n",
       "    'lemma_acc': 0.5,\n",
       "    'dep_uas': None,\n",
       "    'dep_las': None,\n",
       "    'dep_las_per_type': None,\n",
       "    'sents_p': None,\n",
       "    'sents_r': None,\n",
       "    'sents_f': None,\n",
       "    'ents_f': 0.5,\n",
       "    'ents_p': 0.0,\n",
       "    'ents_r': 0.0,\n",
       "    'ents_per_type': None}},\n",
       "  'pretraining': {},\n",
       "  'initialize': {'vectors': '${paths.vectors}',\n",
       "   'init_tok2vec': '${paths.init_tok2vec}',\n",
       "   'vocab_data': '${paths.vocab_path}',\n",
       "   'lookups': None,\n",
       "   'before_init': {'@callbacks': 'replace_tokenizer'},\n",
       "   'after_init': None,\n",
       "   'components': {},\n",
       "   'tokenizer': {}},\n",
       "  'vars': {'include_static_vectors': 'True'}},\n",
       " '_meta': {'lang': 'en',\n",
       "  'name': 'ner_bc5cdr_md',\n",
       "  'version': '0.5.4',\n",
       "  'description': 'Spacy Models for Biomedical Text.',\n",
       "  'author': 'Allen Institute for Artificial Intelligence',\n",
       "  'email': 'ai2-info@allenai.org',\n",
       "  'url': 'https://allenai.github.io/SciSpaCy/',\n",
       "  'license': 'CC BY-SA 3.0',\n",
       "  'spacy_version': '>=3.7.4,<3.8.0',\n",
       "  'spacy_git_version': 'bff8725f4',\n",
       "  'vectors': {'width': 200,\n",
       "   'vectors': 50000,\n",
       "   'keys': 4087446,\n",
       "   'name': 'en_core_sci_md.vectors'},\n",
       "  'labels': {'tok2vec': [],\n",
       "   'tagger': ['$',\n",
       "    \"''\",\n",
       "    ',',\n",
       "    '-LRB-',\n",
       "    '-RRB-',\n",
       "    '.',\n",
       "    ':',\n",
       "    'ADD',\n",
       "    'AFX',\n",
       "    'CC',\n",
       "    'CD',\n",
       "    'DT',\n",
       "    'EX',\n",
       "    'FW',\n",
       "    'HYPH',\n",
       "    'IN',\n",
       "    'JJ',\n",
       "    'JJR',\n",
       "    'JJS',\n",
       "    'LS',\n",
       "    'MD',\n",
       "    'NFP',\n",
       "    'NN',\n",
       "    'NNP',\n",
       "    'NNPS',\n",
       "    'NNS',\n",
       "    'PDT',\n",
       "    'POS',\n",
       "    'PRP',\n",
       "    'PRP$',\n",
       "    'RB',\n",
       "    'RBR',\n",
       "    'RBS',\n",
       "    'RP',\n",
       "    'SYM',\n",
       "    'TO',\n",
       "    'UH',\n",
       "    'VB',\n",
       "    'VBD',\n",
       "    'VBG',\n",
       "    'VBN',\n",
       "    'VBP',\n",
       "    'VBZ',\n",
       "    'WDT',\n",
       "    'WP',\n",
       "    'WP$',\n",
       "    'WRB',\n",
       "    'XX',\n",
       "    '``'],\n",
       "   'attribute_ruler': [],\n",
       "   'lemmatizer': [],\n",
       "   'parser': ['ROOT',\n",
       "    'acl',\n",
       "    'acl:relcl',\n",
       "    'acomp',\n",
       "    'advcl',\n",
       "    'advmod',\n",
       "    'amod',\n",
       "    'amod@nmod',\n",
       "    'appos',\n",
       "    'attr',\n",
       "    'aux',\n",
       "    'auxpass',\n",
       "    'case',\n",
       "    'cc',\n",
       "    'cc:preconj',\n",
       "    'ccomp',\n",
       "    'compound',\n",
       "    'compound:prt',\n",
       "    'conj',\n",
       "    'cop',\n",
       "    'csubj',\n",
       "    'dative',\n",
       "    'dep',\n",
       "    'det',\n",
       "    'det:predet',\n",
       "    'dobj',\n",
       "    'expl',\n",
       "    'intj',\n",
       "    'mark',\n",
       "    'meta',\n",
       "    'mwe',\n",
       "    'neg',\n",
       "    'nmod',\n",
       "    'nmod:npmod',\n",
       "    'nmod:poss',\n",
       "    'nmod:tmod',\n",
       "    'nsubj',\n",
       "    'nsubjpass',\n",
       "    'nummod',\n",
       "    'parataxis',\n",
       "    'pcomp',\n",
       "    'pobj',\n",
       "    'preconj',\n",
       "    'predet',\n",
       "    'prep',\n",
       "    'punct',\n",
       "    'quantmod',\n",
       "    'xcomp'],\n",
       "   'ner': ['CHEMICAL', 'DISEASE']},\n",
       "  'pipeline': ['tok2vec',\n",
       "   'tagger',\n",
       "   'attribute_ruler',\n",
       "   'lemmatizer',\n",
       "   'parser',\n",
       "   'ner'],\n",
       "  'components': ['tok2vec',\n",
       "   'tagger',\n",
       "   'attribute_ruler',\n",
       "   'lemmatizer',\n",
       "   'parser',\n",
       "   'ner'],\n",
       "  'disabled': [],\n",
       "  'performance': {'tag_acc': 0.0,\n",
       "   'lemma_acc': 0.0,\n",
       "   'dep_uas': 0.0,\n",
       "   'dep_las': 0.0,\n",
       "   'dep_las_per_type': 0.0,\n",
       "   'sents_p': 0.0,\n",
       "   'sents_r': 0.0,\n",
       "   'sents_f': 0.0,\n",
       "   'ents_f': 0.8531055233,\n",
       "   'ents_p': 0.867934842,\n",
       "   'ents_r': 0.8387744321,\n",
       "   'ents_per_type': {'CHEMICAL': {'p': 0.9067829457000001,\n",
       "     'r': 0.8778611632000001,\n",
       "     'f': 0.8920877026},\n",
       "    'DISEASE': {'p': 0.8176573865000001,\n",
       "     'r': 0.7883917775,\n",
       "     'f': 0.8027579414}},\n",
       "   'ner_loss': 1998.7021621001},\n",
       "  'sources': ['BC5CDR', 'OntoNotes 5', 'Common Crawl', 'GENIA 1.0'],\n",
       "  'requirements': []},\n",
       " '_path': PosixPath('/home/data/t200404/software/anaconda3/envs/python37_tsf_3/lib/python3.7/site-packages/en_ner_bc5cdr_md/en_ner_bc5cdr_md-0.5.4'),\n",
       " '_optimizer': None,\n",
       " '_pipe_meta': {'tok2vec': FactoryMeta(factory='tok2vec', default_config={'model': {'@architectures': 'spacy.HashEmbedCNN.v2', 'pretrained_vectors': None, 'width': 96, 'depth': 4, 'embed_size': 2000, 'window_size': 1, 'maxout_pieces': 3, 'subword_features': True}}, assigns=['doc.tensor'], requires=[], retokenizes=False, scores=[], default_score_weights={}),\n",
       "  'tagger': FactoryMeta(factory='tagger', default_config={'model': {'@architectures': 'spacy.Tagger.v2', 'tok2vec': {'@architectures': 'spacy.HashEmbedCNN.v2', 'pretrained_vectors': None, 'width': 96, 'depth': 4, 'embed_size': 2000, 'window_size': 1, 'maxout_pieces': 3, 'subword_features': True}}, 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, 'neg_prefix': '!', 'label_smoothing': 0.0}, assigns=['token.tag'], requires=[], retokenizes=False, scores=['tag_acc'], default_score_weights={'tag_acc': 1.0}),\n",
       "  'attribute_ruler': FactoryMeta(factory='attribute_ruler', default_config={'validate': False, 'scorer': {'@scorers': 'spacy.attribute_ruler_scorer.v1'}}, assigns=[], requires=[], retokenizes=False, scores=[], default_score_weights={}),\n",
       "  'lemmatizer': FactoryMeta(factory='lemmatizer', default_config={'model': None, 'mode': 'rule', 'overwrite': False, 'scorer': {'@scorers': 'spacy.lemmatizer_scorer.v1'}}, assigns=['token.lemma'], requires=[], retokenizes=False, scores=['lemma_acc'], default_score_weights={'lemma_acc': 1.0}),\n",
       "  'parser': FactoryMeta(factory='parser', default_config={'moves': None, 'update_with_oracle_cut_size': 100, 'learn_tokens': False, 'min_action_freq': 30, 'model': {'@architectures': 'spacy.TransitionBasedParser.v2', 'state_type': 'parser', 'extra_state_tokens': False, 'hidden_width': 64, 'maxout_pieces': 2, 'use_upper': True, 'tok2vec': {'@architectures': 'spacy.HashEmbedCNN.v2', 'pretrained_vectors': None, 'width': 96, 'depth': 4, 'embed_size': 2000, 'window_size': 1, 'maxout_pieces': 3, 'subword_features': True}}, 'scorer': {'@scorers': 'spacy.parser_scorer.v1'}}, assigns=['token.dep', 'token.head', 'token.is_sent_start', 'doc.sents'], requires=[], retokenizes=False, scores=['dep_uas', 'dep_las', 'dep_las_per_type', 'sents_p', 'sents_r', 'sents_f'], default_score_weights={'dep_uas': 0.5, 'dep_las': 0.5, 'dep_las_per_type': None, 'sents_p': None, 'sents_r': None, 'sents_f': 0.0}),\n",
       "  'ner': FactoryMeta(factory='ner', default_config={'moves': None, 'update_with_oracle_cut_size': 100, 'model': {'@architectures': 'spacy.TransitionBasedParser.v2', 'state_type': 'ner', 'extra_state_tokens': False, 'hidden_width': 64, 'maxout_pieces': 2, 'use_upper': True, 'tok2vec': {'@architectures': 'spacy.HashEmbedCNN.v2', 'pretrained_vectors': None, 'width': 96, 'depth': 4, 'embed_size': 2000, 'window_size': 1, 'maxout_pieces': 3, 'subword_features': True}}, 'incorrect_spans_key': None, 'scorer': {'@scorers': 'spacy.ner_scorer.v1'}}, assigns=['doc.ents', 'token.ent_iob', 'token.ent_type'], requires=[], retokenizes=False, scores=['ents_f', 'ents_p', 'ents_r', 'ents_per_type'], default_score_weights={'ents_f': 1.0, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_per_type': None}),\n",
       "  'abbreviation_detector': FactoryMeta(factory='abbreviation_detector', default_config={}, assigns=[], requires=[], retokenizes=False, scores=[], default_score_weights={})},\n",
       " '_pipe_configs': {'tok2vec': {'factory': 'tok2vec',\n",
       "   'model': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "    'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "     'width': 96,\n",
       "     'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY', 'IS_SPACE'],\n",
       "     'rows': [5000, 1000, 2500, 2500, 50, 50],\n",
       "     'include_static_vectors': 'True'},\n",
       "    'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "     'width': 96,\n",
       "     'depth': 4,\n",
       "     'window_size': 1,\n",
       "     'maxout_pieces': 3}}},\n",
       "  'tagger': {'factory': 'tagger',\n",
       "   'label_smoothing': 0.0,\n",
       "   'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "    'nO': None,\n",
       "    'normalize': 'False',\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "     'width': 96,\n",
       "     'upstream': '*'}},\n",
       "   'neg_prefix': '!',\n",
       "   'overwrite': False,\n",
       "   'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}},\n",
       "  'attribute_ruler': {'factory': 'attribute_ruler',\n",
       "   'scorer': {'@scorers': 'spacy.attribute_ruler_scorer.v1'},\n",
       "   'validate': False},\n",
       "  'lemmatizer': {'factory': 'lemmatizer',\n",
       "   'mode': 'rule',\n",
       "   'model': None,\n",
       "   'overwrite': False,\n",
       "   'scorer': {'@scorers': 'spacy.lemmatizer_scorer.v1'}},\n",
       "  'parser': {'factory': 'parser',\n",
       "   'learn_tokens': False,\n",
       "   'min_action_freq': 30,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'parser',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 128,\n",
       "    'maxout_pieces': 3,\n",
       "    'use_upper': True,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "     'width': 96,\n",
       "     'upstream': '*'}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.parser_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100},\n",
       "  'ner': {'factory': 'ner',\n",
       "   'incorrect_spans_key': None,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'ner',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 128,\n",
       "    'maxout_pieces': 3,\n",
       "    'use_upper': True,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "     'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "      'width': 96,\n",
       "      'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "      'rows': [5000, 2500, 2500, 2500, 100],\n",
       "      'include_static_vectors': '${vars.include_static_vectors}'},\n",
       "     'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "      'width': 96,\n",
       "      'depth': 4,\n",
       "      'window_size': 1,\n",
       "      'maxout_pieces': 3}}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100},\n",
       "  'abbreviation_detector': {'make_serializable': False,\n",
       "   'factory': 'abbreviation_detector'}},\n",
       " 'vocab': <spacy.vocab.Vocab at 0x7f9132cc8b90>,\n",
       " '_components': [('tok2vec',\n",
       "   <spacy.pipeline.tok2vec.Tok2Vec at 0x7f90e70374b0>),\n",
       "  ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f90e70370c0>),\n",
       "  ('attribute_ruler',\n",
       "   <spacy.pipeline.attributeruler.AttributeRuler at 0x7f9132beafa0>),\n",
       "  ('lemmatizer',\n",
       "   <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f9132abf370>),\n",
       "  ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f9093c53550>),\n",
       "  ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f9093c531d0>),\n",
       "  ('abbreviation_detector',\n",
       "   <scispacy.abbreviation.AbbreviationDetector at 0x7f9096f59c90>)],\n",
       " '_disabled': set(),\n",
       " 'max_length': 1000000,\n",
       " 'tokenizer': <spacy.tokenizer.Tokenizer at 0x7f95fb115910>,\n",
       " 'batch_size': 1000,\n",
       " 'default_error_handler': <function spacy.util.raise_error(proc_name, proc, docs, e)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(nlp,'tok2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(nlp.Defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Language.add_pipe of <spacy.lang.en.English object at 0x7f9132e76fd0>>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\t[unused2]\n",
      "go\t[unused2]\n",
      "to\t[unused2]\n",
      ":\t[unused2]\n",
      "p\t[PAD]\n",
      "##oly\t[PAD]\n",
      "##ch\t[PAD]\n",
      "##lor\t[unused1]\n",
      "##inated\t[unused1]\n",
      "di\t[unused1]\n",
      "##ben\t[unused1]\n",
      "##zo\t[unused1]\n",
      "-\t[unused1]\n",
      "p\t[unused1]\n",
      "-\t[unused1]\n",
      "di\t[unused1]\n",
      "##ox\t[unused1]\n",
      "##ins\t[unused2]\n",
      "(\t[unused2]\n",
      "p\t[unused2]\n",
      "##c\t[unused2]\n",
      "##dd\t[unused2]\n",
      "##s\t[unused2]\n",
      ",\t[unused2]\n",
      "di\t[unused2]\n",
      "##ox\t[unused2]\n",
      "##ins\t[unused2]\n",
      ")\t[unused2]\n",
      ",\t[unused2]\n",
      "p\t[unused2]\n",
      "##oly\t[unused2]\n",
      "##ch\t[unused2]\n",
      "##lor\t[unused2]\n",
      "##inated\t[unused2]\n",
      "di\t[unused2]\n",
      "##ben\t[unused2]\n",
      "##zo\t[unused2]\n",
      "##fu\t[unused2]\n",
      "##ran\t[unused2]\n",
      "##s\t[unused2]\n",
      "(\t[unused2]\n",
      "p\t[unused2]\n",
      "##c\t[unused2]\n",
      "##d\t[unused2]\n",
      "##fs\t[unused2]\n",
      ")\t[unused2]\n",
      ",\t[unused2]\n",
      "and\t[unused2]\n",
      "p\t[unused2]\n",
      "##oly\t[unused2]\n",
      "##ch\t[unused2]\n",
      "##lor\t[unused2]\n",
      "##inated\t[unused2]\n",
      "bi\t[unused2]\n",
      "##phe\t[unused2]\n",
      "##ny\t[unused2]\n",
      "##ls\t[unused2]\n",
      "(\t[unused2]\n",
      "p\t[unused2]\n",
      "##c\t[unused2]\n",
      "##bs\t[unused2]\n",
      ")\t[unused2]\n",
      "are\t[unused2]\n",
      "environmental\t[unused2]\n",
      "end\t[unused2]\n",
      "##oc\t[unused2]\n",
      "##rine\t[unused2]\n",
      "disrupt\t[unused2]\n",
      "##ors\t[unused2]\n",
      "that\t[unused2]\n",
      "have\t[unused2]\n",
      "half\t[unused2]\n",
      "-\t[unused2]\n",
      "lives\t[unused2]\n",
      "of\t[unused2]\n",
      "7\t[unused2]\n",
      "–\t[unused2]\n",
      "10\t[unused2]\n",
      "years\t[unused2]\n",
      "in\t[unused2]\n",
      "the\t[unused2]\n",
      "human\t[unused2]\n",
      "body\t[unused2]\n",
      "and\t[unused2]\n",
      "have\t[unused2]\n",
      "toxic\t[unused2]\n",
      "##ities\t[unused2]\n",
      "that\t[unused2]\n",
      "probably\t[unused2]\n",
      "include\t[unused2]\n",
      "car\t[unused2]\n",
      "##cin\t[unused2]\n",
      "##ogen\t[unused2]\n",
      "##esis\t[unused2]\n",
      ".\t[unused2]\n",
      "[SEP]\t[unused2]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from torch.nn import Softmax\n",
    "\n",
    "# 加载预训练的BERT模型和标记器\n",
    "model = BertForTokenClassification.from_pretrained(\"./output/MetabolismNER/\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./output/MetabolismNER/\")\n",
    "\n",
    "# 要识别的文本\n",
    "text = \"Go to: Polychlorinated dibenzo-p -dioxins (PCDDs, dioxins), polychlorinated dibenzofurans (PCDFs), and polychlorinated biphenyls (PCBs) are environmental endocrine disruptors that have half-lives of 7–10 years in the human body and have toxicities that probably include carcinogenesis.\"\n",
    "\n",
    "# 将文本分词并添加特殊标记\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "# 将标记转换为模型输入的索引\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "# 推理模式\n",
    "model.eval()\n",
    "\n",
    "# 使用模型进行推理\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs[0]\n",
    "\n",
    "# 对输出进行softmax处理\n",
    "softmax = Softmax(dim=2)\n",
    "probs = softmax(logits)\n",
    "\n",
    "# 获取最高概率的标签\n",
    "preds = torch.argmax(probs, dim=2)\n",
    "\n",
    "# 获取预测的标签并将其转换回实体\n",
    "pred_labels = [tokenizer.convert_ids_to_tokens(pred.item()) for pred in preds[0]]\n",
    "\n",
    "# 显示识别结果\n",
    "for token, label in zip(tokens, pred_labels):\n",
    "    print(f\"{token}\\t{label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37_tsf_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
